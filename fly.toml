app = "docu-mate-ollama"
primary_region = "ams"

[build]
  image = "ollama/ollama:latest"

[http_service]
  internal_port = 11434
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1

[processes]
  app = "sh -c 'ollama serve & sleep 10 && ollama pull llama3.2:latest && tail -f /dev/null'"

[[vm]]
  memory = '2gb'
  cpu_kind = 'shared'
  cpus = 1

[mounts]
  source = "ollama_data"
  destination = "/root/.ollama"


